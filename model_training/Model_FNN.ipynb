{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>fraudulent</th>\n",
       "      <th>has_location</th>\n",
       "      <th>has_employment_type</th>\n",
       "      <th>has_required_experience</th>\n",
       "      <th>has_required_education</th>\n",
       "      <th>has_industry</th>\n",
       "      <th>...</th>\n",
       "      <th>city_ wilmington</th>\n",
       "      <th>city_ woodbridge</th>\n",
       "      <th>city_ woodruff</th>\n",
       "      <th>city_ worcester</th>\n",
       "      <th>city_ İstanbul</th>\n",
       "      <th>city_ Αthens</th>\n",
       "      <th>city_ Αθήνα</th>\n",
       "      <th>city_ ΕΛΛΗΝΙΚΟ</th>\n",
       "      <th>city_ 마포구 동교동</th>\n",
       "      <th>city_Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17875</th>\n",
       "      <td>17876</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17876</th>\n",
       "      <td>17877</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17877</th>\n",
       "      <td>17878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17878</th>\n",
       "      <td>17879</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17879</th>\n",
       "      <td>17880</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17880 rows × 14818 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_id  telecommuting  has_company_logo  has_questions  fraudulent  \\\n",
       "0           1              0                 1              0           0   \n",
       "1           2              0                 1              0           0   \n",
       "2           3              0                 1              0           0   \n",
       "3           4              0                 1              0           0   \n",
       "4           5              0                 1              1           0   \n",
       "...       ...            ...               ...            ...         ...   \n",
       "17875   17876              0                 1              1           0   \n",
       "17876   17877              0                 1              1           0   \n",
       "17877   17878              0                 0              0           0   \n",
       "17878   17879              0                 0              1           0   \n",
       "17879   17880              0                 1              1           0   \n",
       "\n",
       "       has_location  has_employment_type  has_required_experience  \\\n",
       "0                 1                    1                        1   \n",
       "1                 1                    1                        1   \n",
       "2                 1                    0                        0   \n",
       "3                 1                    1                        1   \n",
       "4                 1                    1                        1   \n",
       "...             ...                  ...                      ...   \n",
       "17875             1                    1                        1   \n",
       "17876             1                    1                        1   \n",
       "17877             1                    1                        0   \n",
       "17878             1                    1                        1   \n",
       "17879             1                    1                        1   \n",
       "\n",
       "       has_required_education  has_industry  ...  city_ wilmington  \\\n",
       "0                           0             0  ...               0.0   \n",
       "1                           0             1  ...               0.0   \n",
       "2                           0             0  ...               0.0   \n",
       "3                           1             1  ...               0.0   \n",
       "4                           1             1  ...               0.0   \n",
       "...                       ...           ...  ...               ...   \n",
       "17875                       0             1  ...               0.0   \n",
       "17876                       1             1  ...               0.0   \n",
       "17877                       0             0  ...               0.0   \n",
       "17878                       1             1  ...               0.0   \n",
       "17879                       0             1  ...               0.0   \n",
       "\n",
       "       city_ woodbridge   city_ woodruff  city_ worcester  city_ İstanbul  \\\n",
       "0                    0.0             0.0              0.0             0.0   \n",
       "1                    0.0             0.0              0.0             0.0   \n",
       "2                    0.0             0.0              0.0             0.0   \n",
       "3                    0.0             0.0              0.0             0.0   \n",
       "4                    0.0             0.0              0.0             0.0   \n",
       "...                  ...             ...              ...             ...   \n",
       "17875                0.0             0.0              0.0             0.0   \n",
       "17876                0.0             0.0              0.0             0.0   \n",
       "17877                0.0             0.0              0.0             0.0   \n",
       "17878                0.0             0.0              0.0             0.0   \n",
       "17879                0.0             0.0              0.0             0.0   \n",
       "\n",
       "       city_ Αthens  city_ Αθήνα  city_ ΕΛΛΗΝΙΚΟ  city_ 마포구 동교동  city_Unknown  \n",
       "0               0.0          0.0             0.0            0.0           0.0  \n",
       "1               0.0          0.0             0.0            0.0           0.0  \n",
       "2               0.0          0.0             0.0            0.0           0.0  \n",
       "3               0.0          0.0             0.0            0.0           0.0  \n",
       "4               0.0          0.0             0.0            0.0           0.0  \n",
       "...             ...          ...             ...            ...           ...  \n",
       "17875           0.0          0.0             0.0            0.0           0.0  \n",
       "17876           0.0          0.0             0.0            0.0           0.0  \n",
       "17877           0.0          0.0             0.0            0.0           0.0  \n",
       "17878           0.0          0.0             0.0            0.0           0.0  \n",
       "17879           0.0          0.0             0.0            0.0           0.0  \n",
       "\n",
       "[17880 rows x 14818 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data_cleaned.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['fraudulent', 'job_id'])\n",
    "y = df['fraudulent'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X.values.astype(np.float32), dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# Create a TensorDataset\n",
    "full_dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# Split into train (80%) and test (20%) datasets\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "trainset, testset = random_split(full_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 11443\n",
      "Validation dataset size: 2861\n",
      "Test dataset size: 3576\n",
      "Trainloader: 90\n",
      "Valloader: 23\n",
      "Testloader: 28\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.8 * len(trainset))\n",
    "val_size = len(trainset) - train_size\n",
    "\n",
    "# Split the trainset\n",
    "train_dataset_new, val_dataset = random_split(trainset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoader objects\n",
    "batch_size = 128\n",
    "\n",
    "trainloader = DataLoader(train_dataset_new, batch_size=batch_size, shuffle=True)\n",
    "valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Check sizes to confirm splitting\n",
    "print(f\"Train dataset size: {len(train_dataset_new)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(testset)}\")\n",
    "\n",
    "print(f\"Trainloader: {len(trainloader)}\")\n",
    "print(f\"Valloader: {len(valloader)}\")\n",
    "print(f\"Testloader: {len(testloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.3304, Accuracy: 92.29%\n",
      "Validation Accuracy: 95.04%\n",
      "Epoch 2/10, Loss: 0.2974, Accuracy: 94.98%\n",
      "Validation Accuracy: 95.00%\n",
      "Epoch 3/10, Loss: 0.2832, Accuracy: 95.06%\n",
      "Validation Accuracy: 95.00%\n",
      "Epoch 4/10, Loss: 0.2876, Accuracy: 95.08%\n",
      "Validation Accuracy: 95.00%\n",
      "Epoch 5/10, Loss: 0.2673, Accuracy: 95.07%\n",
      "Validation Accuracy: 95.00%\n",
      "Epoch 6/10, Loss: 0.2575, Accuracy: 95.08%\n",
      "Validation Accuracy: 95.00%\n",
      "Epoch 7/10, Loss: 0.2506, Accuracy: 95.08%\n",
      "Validation Accuracy: 95.00%\n",
      "Epoch 8/10, Loss: 0.2395, Accuracy: 95.08%\n",
      "Validation Accuracy: 95.00%\n",
      "Epoch 9/10, Loss: 0.2416, Accuracy: 95.08%\n",
      "Validation Accuracy: 95.00%\n",
      "Epoch 10/10, Loss: 0.2356, Accuracy: 95.08%\n",
      "Validation Accuracy: 95.00%\n",
      "Average Training Loss: 0.2691\n",
      "Average Training Accuracy: 94.79%\n",
      "Test Accuracy: 95.53%\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "AUPRC (Area Under the Precision-Recall Curve): 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiahui\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "class FNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)  # Increased hidden layer size\n",
    "        self.fc2 = nn.Linear(256, 128)        # Increased hidden layer size\n",
    "        self.fc3 = nn.Linear(128, 64)         # Hidden layer\n",
    "        self.fc4 = nn.Linear(64, 32)          # Hidden layer\n",
    "        self.fc5 = nn.Linear(32, 1)           # Output layer\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)        # Dropout for regularization\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc5(x))  # Sigmoid for binary classification\n",
    "        return x\n",
    "\n",
    "# Model initialization\n",
    "input_dim = train_dataset_new[0][0].shape[0]  # Get input dimension from dataset\n",
    "model = FNN(input_dim)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Loss function (Binary Cross-Entropy for binary classification)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Initialize variables to store average metrics\n",
    "total_train_loss = 0\n",
    "total_train_accuracy = 0\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for data, target in trainloader:\n",
    "        optimizer.zero_grad() \n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(outputs, target.view(-1, 1).float())  # Reshape target to (batch_size, 1)\n",
    "        loss.backward()  # Backpropagate\n",
    "        optimizer.step()  # Update model parameters\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Calculate training accuracy, Binary classification: threshold at 0.5\n",
    "        predictions = (outputs > 0.5).float()\n",
    "        correct_train += (predictions.view(-1) == target.view(-1)).sum().item()\n",
    "        total_train += target.size(0)\n",
    "\n",
    "    # Calculate average training loss and accuracy\n",
    "    avg_train_loss = epoch_loss / len(trainloader)\n",
    "    avg_train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "    # Accumulate values for average over all epochs\n",
    "    total_train_loss += avg_train_loss\n",
    "    total_train_accuracy += avg_train_accuracy\n",
    "\n",
    "    # Print training metrics for this epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss:.4f}, Accuracy: {avg_train_accuracy:.2f}%\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in valloader:\n",
    "            outputs = model(data)\n",
    "            predictions = (outputs > 0.5).float()\n",
    "            correct_val += (predictions.view(-1) == target.view(-1)).sum().item()\n",
    "            total_val += target.size(0)\n",
    "\n",
    "    # Calculate validation accuracy\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "# Calculate the average loss and accuracy over all epochs\n",
    "avg_train_loss_over_epochs = total_train_loss / num_epochs\n",
    "avg_train_accuracy_over_epochs = total_train_accuracy / num_epochs\n",
    "\n",
    "print(f\"Average Training Loss: {avg_train_loss_over_epochs:.4f}\")\n",
    "print(f\"Average Training Accuracy: {avg_train_accuracy_over_epochs:.2f}%\")\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "predictions_list = []\n",
    "targets_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        outputs = model(data)\n",
    "        predictions = (outputs > 0.5).float()\n",
    "        predictions_list.extend(predictions.cpu().numpy())\n",
    "        targets_list.extend(target.cpu().numpy())\n",
    "        correct_test += (predictions.view(-1) == target.view(-1)).sum().item()\n",
    "        total_test += target.size(0)\n",
    "\n",
    "# Test accuracy\n",
    "test_accuracy = 100 * correct_test / total_test\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Calculate other metrics like precision, recall, and F1 score\n",
    "precision = precision_score(targets_list, predictions_list)\n",
    "recall = recall_score(targets_list, predictions_list)\n",
    "f1 = f1_score(targets_list, predictions_list)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# Calculate precision-recall curve and AUPRC (Area Under the Precision-Recall Curve)\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(targets_list, predictions_list)\n",
    "auprc = auc(recall_vals, precision_vals)\n",
    "\n",
    "print(f\"AUPRC (Area Under the Precision-Recall Curve): {auprc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.2305, Accuracy: 94.26%\n",
      "Validation Accuracy: 95.00%\n",
      "Epoch 2/10, Loss: 0.1445, Accuracy: 95.09%\n",
      "Validation Accuracy: 95.00%\n",
      "Epoch 3/10, Loss: 0.1171, Accuracy: 95.36%\n",
      "Validation Accuracy: 95.70%\n",
      "Epoch 4/10, Loss: 0.0996, Accuracy: 96.04%\n",
      "Validation Accuracy: 95.74%\n",
      "Epoch 5/10, Loss: 0.0959, Accuracy: 96.61%\n",
      "Validation Accuracy: 97.55%\n",
      "Epoch 6/10, Loss: 0.0746, Accuracy: 97.37%\n",
      "Validation Accuracy: 97.87%\n",
      "Epoch 7/10, Loss: 0.0829, Accuracy: 97.15%\n",
      "Validation Accuracy: 97.83%\n",
      "Epoch 8/10, Loss: 0.0538, Accuracy: 98.17%\n",
      "Validation Accuracy: 97.31%\n",
      "Epoch 9/10, Loss: 0.0564, Accuracy: 98.18%\n",
      "Validation Accuracy: 97.97%\n",
      "Epoch 10/10, Loss: 0.0699, Accuracy: 97.91%\n",
      "Validation Accuracy: 96.54%\n",
      "Average Training Loss: 0.1025\n",
      "Average Training Accuracy: 96.61%\n",
      "Test Accuracy: 96.73%\n",
      "Precision: 0.96\n",
      "Recall: 0.28\n",
      "F1 Score: 0.43\n",
      "AUPRC (Area Under the Precision-Recall Curve): 0.64\n"
     ]
    }
   ],
   "source": [
    "class FNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)  # Increased hidden layer size\n",
    "        self.fc2 = nn.Linear(256, 128)        # Increased hidden layer size\n",
    "        self.fc3 = nn.Linear(128, 64)         # Hidden layer\n",
    "        self.fc4 = nn.Linear(64, 32)          # Hidden layer\n",
    "        self.fc5 = nn.Linear(32, 1)           # Output layer\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)        # Dropout for regularization\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc5(x))  # Sigmoid for binary classification\n",
    "        return x\n",
    "\n",
    "# Model initialization\n",
    "input_dim = train_dataset_new[0][0].shape[0]  # Get input dimension from dataset\n",
    "model = FNN(input_dim)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Loss function (Binary Cross-Entropy for binary classification)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Initialize variables to store average metrics\n",
    "total_train_loss = 0\n",
    "total_train_accuracy = 0\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for data, target in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(outputs, target.view(-1, 1).float())  # Reshape target to (batch_size, 1)\n",
    "        loss.backward()  # Backpropagate\n",
    "        optimizer.step()  # Update model parameters\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        predictions = (outputs > 0.5).float()\n",
    "        correct_train += (predictions.view(-1) == target.view(-1)).sum().item()\n",
    "        total_train += target.size(0)\n",
    "\n",
    "    # Calculate average training loss and accuracy\n",
    "    avg_train_loss = epoch_loss / len(trainloader)\n",
    "    avg_train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "    # Accumulate values for average over all epochs\n",
    "    total_train_loss += avg_train_loss\n",
    "    total_train_accuracy += avg_train_accuracy\n",
    "\n",
    "    # Print training metrics for this epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss:.4f}, Accuracy: {avg_train_accuracy:.2f}%\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in valloader:\n",
    "            outputs = model(data)\n",
    "            predictions = (outputs > 0.5).float()\n",
    "            correct_val += (predictions.view(-1) == target.view(-1)).sum().item()\n",
    "            total_val += target.size(0)\n",
    "\n",
    "    # Calculate validation accuracy\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "# Calculate the average loss and accuracy over all epochs\n",
    "avg_train_loss_over_epochs = total_train_loss / num_epochs\n",
    "avg_train_accuracy_over_epochs = total_train_accuracy / num_epochs\n",
    "\n",
    "print(f\"Average Training Loss: {avg_train_loss_over_epochs:.4f}\")\n",
    "print(f\"Average Training Accuracy: {avg_train_accuracy_over_epochs:.2f}%\")\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "predictions_list = []\n",
    "targets_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        outputs = model(data)\n",
    "        predictions = (outputs > 0.5).float()\n",
    "        predictions_list.extend(predictions.cpu().numpy())\n",
    "        targets_list.extend(target.cpu().numpy())\n",
    "        correct_test += (predictions.view(-1) == target.view(-1)).sum().item()\n",
    "        total_test += target.size(0)\n",
    "\n",
    "# Test accuracy\n",
    "test_accuracy = 100 * correct_test / total_test\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Calculate other metrics like precision, recall, and F1 score\n",
    "precision = precision_score(targets_list, predictions_list)\n",
    "recall = recall_score(targets_list, predictions_list)\n",
    "f1 = f1_score(targets_list, predictions_list)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# Calculate precision-recall curve and AUPRC (Area Under the Precision-Recall Curve)\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(targets_list, predictions_list)\n",
    "auprc = auc(recall_vals, precision_vals)\n",
    "\n",
    "print(f\"AUPRC (Area Under the Precision-Recall Curve): {auprc:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
